{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6577c453-d8ce-4056-ac01-96baf8089a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify best run.\n",
      "Read outputs.\n",
      "Plot.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This code plots the parameter trace during a parameter estimation process.\n",
    "# Note: This code plots the incomplete trace of samples because it reads sampels from ostOutput.txt.\n",
    "# Only the parameter sets that improve the objective function in comparison with the previous parameter set are plotted.\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, argparse, datetime\n",
    "from glob import glob\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# Function to extract a given setting from the configuration file\n",
    "def read_from_control(control_file, setting):\n",
    "    \n",
    "    # Open 'control_active.txt' and locate the line with setting\n",
    "    with open(control_file) as ff:\n",
    "        for line in ff:\n",
    "            line = line.strip()\n",
    "            if line.startswith(setting):\n",
    "                break\n",
    "    # Extract the setting's value\n",
    "    substring = line.split('|',1)[1].split('#',1)[0].strip() \n",
    "    # Return this value    \n",
    "    return substring\n",
    "\n",
    "def read_obs_flow(obs_file, StartDate, EndDate):\n",
    "    df_obs = pd.read_csv(obs_file, index_col='Date', na_values=[\"-99.0\",\"-999.0\",\"-9999.0\"],\n",
    "                         parse_dates=True, infer_datetime_format=True)  \n",
    "    df_obs.columns = ['obs']\n",
    "    \n",
    "    # convert obs from cfs to cms\n",
    "    if obs_unit == 'cfs':\n",
    "        df_obs = df_obs/35.3147     \n",
    "    df_obs = df_obs.truncate(before=StartDate, after=EndDate)\n",
    "    return df_obs\n",
    "\n",
    "def read_route_output(route_outFile, StartDate, EndDate):\n",
    "    simVarName = 'IRFroutedRunoff'\n",
    "    with xr.open_dataset(route_outFile) as f:\n",
    "        time = f['time'].values\n",
    "        sim  = f[simVarName][:,(q_seg_index-1)].values #(time, segments)\n",
    "        df_sim = pd.DataFrame({'sim':sim},index = time)\n",
    "        df_sim.index = pd.to_datetime(df_sim.index)\n",
    "    df_sim = df_sim.truncate(before=StartDate, after=EndDate)\n",
    "    return df_sim\n",
    "\n",
    "def read_summa_output(summa_outFile, StartDate, EndDate):\n",
    "    with xr.open_dataset(summa_outFile) as f:\n",
    "        time = f['time'].values\n",
    "        stateVar_list = list(f.keys())\n",
    "        stateVar_name_list = stateVar_list.copy()\n",
    "        for x in ['time','hru','gru','hruId','gruId']:\n",
    "            if x in stateVar_list:\n",
    "                stateVar_name_list.remove(x)\n",
    "        stateVar_num = len(stateVar_name_list)\n",
    "        \n",
    "        # read each state variable and calculate GRU/HRU mean value\n",
    "        for i in range(stateVar_num):\n",
    "            stateVarName = stateVar_name_list[i]\n",
    "            stateVar_long_name = f[stateVarName].attrs['long_name']\n",
    "            stateVar_units = f[stateVarName].attrs['units']\n",
    "            stateVar_data = np.nanmean(f[stateVarName].values, axis=1) #(time,hru) or (time,gru)\n",
    "            \n",
    "            # save state data into dataframe\n",
    "            if i == 0:\n",
    "                df_state = pd.DataFrame({stateVarName:stateVar_data},index = time)\n",
    "                df_sim.index = pd.to_datetime(df_sim.index)         \n",
    "                stateVar_long_name_list = [stateVar_long_name]\n",
    "                stateVar_units_list = [stateVar_units]\n",
    "            else:\n",
    "                df_state[stateVarName] = stateVar_data\n",
    "                stateVar_long_name_list.append(stateVar_long_name)\n",
    "                stateVar_units_list.append(stateVar_units)    \n",
    "\n",
    "    # (2) truncate state dataframe based on time\n",
    "    df_state = df_state.truncate(before=StartDate, after=EndDate)\n",
    "    df_state = df_state.dropna()\n",
    "    return df_state, stateVar_num, stateVar_name_list, stateVar_long_name_list, stateVar_units_list\n",
    "\n",
    "# main\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # ----------------------------- Settings ------------------------------        \n",
    "    # calib inputs\n",
    "    root_path = '/home/h294liu/project/proj/5_summaCalib'  # root path where parameter estimation will be stored.\n",
    "    domain_name = 'BowAtBanff_LA_calib' #'BowAtBanff' #'BowAtBanff_LA_calib'\n",
    "    \n",
    "    calib_basename = 'GLUE' #SCE #GA #DDS #GLUE  \n",
    "    default_model_folder = 'BowAtBanff_LA' #'BowAtBanff_LA' #'BowAtBanff_default'\n",
    "    default_model_output_folder = 'simulations_2010_2013'\n",
    "    outFilePrefix = 'run1'\n",
    "\n",
    "    calib_output_path = os.path.join(root_path, domain_name,calib_basename+'_summary')\n",
    "    default_output_path = os.path.join(root_path, default_model_folder)\n",
    "\n",
    "    # identify plot output path and file\n",
    "    output_path = os.path.join(calib_output_path, 'analysis', '10_plot_state_compare')\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    ofile_fig = os.path.join(output_path, '%s_best_state.png'%(calib_basename))   # output plot figure\n",
    "    ofile_txt = os.path.join(output_path, '%s_best_summary.txt'%(calib_basename)) # output best param information\n",
    "   \n",
    "    # --------------------------- End settings -----------------------------        \n",
    "    \n",
    "    print('Identify best run.')\n",
    "    # 1. identify run number of the best parameter set\n",
    "    data = np.loadtxt(os.path.join(calib_output_path, 'OstModel.txt'), delimiter='\\t', usecols=[0,1], skiprows=1)\n",
    "    best_run_id = int(data[np.argmin(data[:,1]),0])\n",
    "    \n",
    "    # 2. identify summa and route simualtion output from the best run and default run\n",
    "    best_run_path = os.path.join(calib_output_path, 'runs', 'run'+str(best_run_id))\n",
    "    summa_outFile = os.path.join(best_run_path, outFilePrefix+'_day.nc')\n",
    "    route_outFile = os.path.join(best_run_path, outFilePrefix+'.mizuRoute.nc')\n",
    "    \n",
    "    summa_outFile_default = os.path.join(default_output_path, 'model', default_model_output_folder, outFilePrefix,\n",
    "                                         'SUMMA', outFilePrefix+'_day.nc')\n",
    "    route_outFile_default = os.path.join(default_output_path, 'model', default_model_output_folder, outFilePrefix,\n",
    "                                         'mizuRoute', outFilePrefix+'.mizuRoute.nc')\n",
    "    \n",
    "    # 3. read control_active.txt for route segment id, observations, and time series configs.\n",
    "    control_file = os.path.join(default_output_path, 'calib/control_active.txt')\n",
    "    q_seg_index = int(read_from_control(control_file, 'q_seg_index')) # start from one.   \n",
    "    obs_file = read_from_control(control_file, 'obs_file')\n",
    "    obs_unit = read_from_control(control_file, 'obs_unit')\n",
    "\n",
    "    statStartDate = read_from_control(control_file, 'statStartDate') \n",
    "    statEndDate = read_from_control(control_file, 'statEndDate')\n",
    "\n",
    "    time_format='%Y-%m-%d'\n",
    "    statStartDate = datetime.datetime.strptime(statStartDate,time_format) + datetime.timedelta(days=3) # add two days to avoid very bad initial results\n",
    "    statEndDate = datetime.datetime.strptime(statEndDate,time_format)    \n",
    "\n",
    "    print('Read outputs.')\n",
    "    # 4. read best run model outputs\n",
    "    # read observed streamflow\n",
    "    df_obs = read_obs_flow(obs_file, statStartDate, statEndDate)\n",
    "    # read route streamflow          \n",
    "    df_sim = read_route_output(route_outFile, statStartDate, statEndDate)    \n",
    "    # merge the two df based on time index \n",
    "    df_sim_obs = pd.concat([df_obs, df_sim], axis=1)\n",
    "    df_sim_obs = df_sim_obs.dropna()    \n",
    "    # read summa state outputs\n",
    "    df_state,stateVar_num,stateVar_name_list,stateVar_long_name_list,stateVar_units_list\\\n",
    "    = read_summa_output(summa_outFile, statStartDate, statEndDate)\n",
    "\n",
    "    # 5. read default run model outputs\n",
    "    # read route streamflow        \n",
    "    df_sim_default = read_route_output(route_outFile_default, statStartDate, statEndDate)    \n",
    "    # merge the two df based on time index \n",
    "    df_sim_obs_default = pd.concat([df_obs, df_sim_default], axis=1)\n",
    "    df_sim_obs_default = df_sim_obs_default.dropna()       \n",
    "    # read summa state outputs\n",
    "    df_state_default,stateVar_num_default,stateVar_name_list_default,stateVar_long_name_list_default,stateVar_units_list_default \\\n",
    "    = read_summa_output(summa_outFile_default, statStartDate, statEndDate)\n",
    "    \n",
    "    # 6. Plot\n",
    "    print('Plot.')\n",
    "    col_num = 4 #3        \n",
    "    var_plot_total = stateVar_num+1\n",
    "    row_num = int(np.ceil(var_plot_total/float(col_num))) # state(including forcing) + hydrograph\n",
    "    \n",
    "    fig, ax = plt.subplots(row_num,col_num, figsize=(5.5*col_num, 3.54*0.75*row_num))#, constrained_layout=True)\n",
    "    fig.suptitle(domain_name, fontsize='large', fontweight='bold')\n",
    "    dpi_value=80    \n",
    "    ax_id = 0\n",
    "    \n",
    "    # (1) plot hydrograph\n",
    "    ax_id = 0 \n",
    "    iRow = ax_id//col_num\n",
    "    iCol = ax_id%col_num\n",
    "\n",
    "    df_sim_obs_default['obs'].plot(ax=ax[iRow,iCol], linewidth=0.75, markersize=0.0, color='black', alpha=0.6)\n",
    "    df_sim_obs_default['sim'].plot(ax=ax[iRow,iCol], linewidth=0.75, markersize=0.0, color='blue', alpha=0.6)\n",
    "    df_sim_obs['sim'].plot(ax=ax[iRow,iCol], linewidth=0.75, markersize=0.0, color='red', alpha=0.6)\n",
    "    \n",
    "    ax[iRow,iCol].legend([\"Observed\",\"A priori\", \"Calibrated\"], loc='best', fontsize='medium')\n",
    "    ax[iRow,iCol].set_title('('+chr(ord('a') + ax_id) +') ' + 'Hydrograph', fontsize='medium', fontweight='semibold')\n",
    "    ax[iRow,iCol].set_ylabel('Flow (cms)', fontsize='medium')\n",
    "    \n",
    "    # (2) plot states\n",
    "    for j in range(stateVar_num):\n",
    "        # identify subplot variable info\n",
    "        stateVarName = stateVar_name_list[j]\n",
    "        stateVar_long_name = stateVar_long_name_list[j]\n",
    "        stateVar_units = stateVar_units_list[j]\n",
    "\n",
    "        # identify subplot ax\n",
    "        ax_id = 1+j\n",
    "        iRow = ax_id//col_num\n",
    "        iCol = ax_id%col_num\n",
    "\n",
    "        # plot state variables \n",
    "        df_state_default[stateVarName].plot(ax=ax[iRow,iCol], linewidth=0.75, markersize=0.0, color='blue', alpha=0.6)\n",
    "        df_state[stateVarName].plot(ax=ax[iRow,iCol], linewidth=0.75, markersize=0.0, color='red', alpha=0.6)\n",
    "        \n",
    "        title = '('+chr(ord('a') + ax_id) +') ' + stateVarName.replace('scalar','').capitalize()# + \\\n",
    "        #'\\n[ie, ' + stateVar_long_name.rstrip('(instant)').capitalize() + ']'\n",
    "        ax[iRow,iCol].set_title(title, fontsize='medium', fontweight='semibold')\n",
    "        ax[iRow,iCol].set_ylabel('('+stateVar_units+')', fontsize='medium')\n",
    "#         if iRow==0 and iCol==0:\n",
    "#             ax[iRow,iCol].legend([\"A priori\", \"Calibrated\"]);\n",
    "\n",
    "    # (3) make extra suplots blank\n",
    "    for iRow in range(row_num):\n",
    "        for iCol in range(col_num):\n",
    "            ax_id = iRow*col_num + iCol\n",
    "#             date_form = DateFormatter(\"%b-%Y\")\n",
    "#             ax[iRow,iCol].xaxis.set_major_formatter(date_form)\n",
    "            if ax_id >= var_plot_total:\n",
    "                ax[iRow,iCol].axis('off')           \n",
    "\n",
    "    plt.rc('xtick',labelsize='medium')\n",
    "    plt.rc('ytick',labelsize='medium')   \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.95)\n",
    "    fig.savefig(ofile_fig, dpi=dpi_value)\n",
    "    plt.close(fig)  \n",
    "    \n",
    "    # 7. save best run information to ofile_txt\n",
    "    f = open(ofile_txt, 'w')\n",
    "    f.write('Best run ID = %d\\n'%(best_run_id))\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c205d5-8f10-4f2a-92a0-211640e8f508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hl-env",
   "language": "python",
   "name": "hl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
